{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"start\"></a>\n",
    "# **Embedded Convolutional Neural Network - Tutorial Prático**\n",
    "\n",
    "Esta é a parte prática do tutorial de construção de um modelo de colorização de imagens classificadas. Nessa `Notebook`, você será guiado a construir código do modelo **ECNN** e também os códigos necessários para **treinar** o modelo, **testar** acurácia e **aplicar** o modelo para colorir novas imagens.\n",
    "\n",
    "Esse tutorial possuirá pouca teoria, espera-se você já tenha lido a parte teórica nessecessária para entender o que será feito aqui presente em nosso [site](https://rafaeldbo.github.io/project-colorization/context). De qualquer maneira, as sessões necessárias para entendimento de cada etapa desse `Notebook` serão referênciadas para consulta na própria etapa. \n",
    "\n",
    "## **Sumário**\n",
    "\n",
    "1. [Preparando as Imagens](#load_images)\n",
    "2. [Construindo o Modelo](#building_model)\n",
    "\n",
    "    2.1. [Criando a Estrutura do Modelo](#creating_layers)\n",
    "\n",
    "    2.2. [Função \"foward\"](#foward)\n",
    "    \n",
    "    2.3. [Modelo Completo](#ECNN_model)\n",
    "3. [Construindo a Rotina de Treinamento](#train_model)\n",
    "4. [Construindo a Rotina de Testes](#test_model)\n",
    "5. [Aplicando o Modelo](#deploy_model)\n",
    "\n",
    "## **Instalando Dependências**\n",
    " \n",
    "Antes de começarmos, caso não tenha as bibliotecas necessárias, rode a célula abaixo para instala-las ou instale utilizando o arquivo [requirements.txt](https://github.com/rafaeldbo/project-colorization/blob/main/requirements.txt) presente em nosso repositório. É recomendado o uso de um ambiente virtual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Só é necessário rodar esse script uma vez para instalar as dependências necessárias\n",
    "!python -m pip install torch scikit-image matplotlib pandas numpy jupyter ipykernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso possuia **GPU** com suporte ao `cuda` e deseja utiliza-la, verifique se ela já está disponivel utilizando o código abaixo. Caso não esteja, acesse esse [site](https://pytorch.org/get-started/locally/) e escolha a versão do `pytorch` com maior compatibilidade com sua GPU e a instale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versão do torch: 2.5.1+cu124\n",
      "cuda disponivel!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"versão do torch: {torch.__version__}\")\n",
    "print(\"cuda disponivel!\" if torch.cuda.is_available() else \"cuda indisponível :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn, Tensor,  cat, from_numpy, save, load\n",
    "from torch.nn.functional import relu\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2lab\n",
    "\n",
    "from os import path, listdir, mkdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load_images\"></a>\n",
    "## **Preparando as Imagens**\n",
    "\n",
    "A teoria referente a essa etapa está disponível na sessão [Entradas e Saídas do Modelo](https://rafaeldbo.github.io/project-colorization/inputs_outputs) do nosso site.\n",
    "\n",
    "Um ponto importante do modelo que criaremos nesse tutorial é que, após ser treinado por um conjunto de imagens de determinadas dimensões ($largura \\times altura$), ele só poderá ser aplicado em imagens destas mesmas dimensões. Nesse tutorial, utilizaremos as imagens do dataset [Image Colorization Dataset](https://www.kaggle.com/datasets/aayush9753/image-colorization-dataset) que possuem as dimensões $400 \\times 400$, dessa forma, todas as imagens recebidas e \"geradas\" pelo modelo possuirão essas mesmas dimensões. Além disso, como se trata de um modelo que colore imagem caregorizadas, também precisaremos de um arquivos com as categorias de cada imagem. Felizmente nosso time já preparou o aquivo [categories.csv](https://alinsperedu-my.sharepoint.com/:x:/g/personal/rafaeldbo_al_insper_edu_br/ETV6ST4HWAFFhvtF-JJ5HjsB_v9Fe3QacOhVpd3ynIYiyA?e=2W7cAB) exatamente com essa informação. Coloque tanto as pastas de imagens do dataset quanto o arquivo de categorias em uma pasta `data`, para melhor organização.\n",
    "\n",
    "Para preparar as imagens para a utilização pelo nosso modelo precisaremos criar um classe de **dataset** personalisada baseada na classe `Dataset` do `pytorch`. Ela deverá localizar todas a imagens que serão utilizadas pelo modelo e possuir uma função `__getitem__` que  caregará uma imagem de cada vez, fornecendo os dados da imagem e sua categoria. Essa estrutura será imoprtante para que, no futuro, o `DataLoader` seja capaz de utilizar essa classe **dataset** para carregar as imagens dos nossos **Batches** (caso não se lembre do que estamos falando, isso será retomado mais adiante). Para facilitar, já iremos fazer com que ela retorne separadamente o layer L e os layers AB.\n",
    "\n",
    "O código desse dataset personalizado será:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "        images_path: str, # Caminho da pasta onde estão as imagens \n",
    "        categories_file: str, # Caminho do arquivo csv com as categorias das imagens\n",
    "        size: int = -1, # Quantidade de imagens a serem carregadas, sendo -1 para todas\n",
    "    ):\n",
    "        # criando uma lista com os arquivos das imagens\n",
    "        self.images_path = images_path\n",
    "        images = listdir(images_path) # listando os arquivos da pasta\n",
    "        size = size if size > 0 else len(images)\n",
    "        self.images_files = images[:size]\n",
    "        \n",
    "        # criando um dicionário com as categorias das imagens\n",
    "        df = pd.read_csv(path.join(categories_file), delimiter=';') # lendo o arquivo csv\n",
    "        df['category'] = df['category'].fillna(0) # colocando a categoria 0 para as imagens sem categoria, caso existam\n",
    "        self.categories = df.set_index('image')['category'].to_dict() # criando o dicionário\n",
    "\n",
    "    # função que retorna o tamanho do dataset\n",
    "    def __len__(self):\n",
    "        return len(self.images_files)\n",
    "\n",
    "    def __getitem__(self, \n",
    "        index: int, # Índice da imagem a ser carregada\n",
    "    ) -> tuple[Tensor, Tensor, int]:\n",
    "        \n",
    "            # lendo a imagem\n",
    "            img_file = self.images_files[index]\n",
    "            img_path = path.join(self.images_path, img_file)\n",
    "            img = imread(img_path) \n",
    "\n",
    "            # converte a imagem de RGB para LAB\n",
    "            LAB_img = from_numpy(rgb2lab(img)) \n",
    "            LAB_img = LAB_img.permute(2, 0, 1) \n",
    "\n",
    "            # separa os layers\n",
    "            gray_layer = LAB_img[0, :, :].unsqueeze(0) \n",
    "            color_layers = LAB_img[1:, :, :] \n",
    "            \n",
    "            # retornando o layer L, os layers AB e a categoria da imagem\n",
    "            return gray_layer, color_layers, self.categories[img_file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
